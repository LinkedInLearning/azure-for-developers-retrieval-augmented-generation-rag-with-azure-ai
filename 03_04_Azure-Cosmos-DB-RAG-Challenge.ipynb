{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a RAG solution using Azure Cosmos DB Challenge\n",
    "\n",
    "Steps in this notebook:\n",
    "1. Setup Azure Cosmos DB - database, container, policies (vector embedding, full text search, and indexing). \n",
    "- Name the database recipes-database and recipes-container\n",
    "- Vector embeddings must be 3072 in dimension with field called contentVector. \n",
    "- Use the cosine distance function and quantizedFlat type.\n",
    "- Enable full text search in the name and description.\n",
    "2. Create embeddings for recipes.json. \n",
    "- Combined all strings into one variable and compute its embedding.\n",
    "- Use text embedding 3 large \n",
    "3. Upload data to the container\n",
    "- Inspect the data in the container\n",
    "4. Send a query to the search engine to check results\n",
    "- Perform a hybrid search with the contentVector and description field.\n",
    "5. Send query results to a language model to generate response\n",
    "Note: Perform vector search for this exercise if your database does not support hybrid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install openai\n",
    "%pip install python-dotenv\n",
    "%pip install azure-core\n",
    "%pip install azure-cosmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Azure configurations\n",
    "\n",
    "You always need to run this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv() # take environment variables from .env.\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "azure_openai_deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "azure_openai_embeddings_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\")\n",
    "azure_openai_api_version = \"2024-10-01-preview\"\n",
    "azure_openai_embeddings_size = 3072\n",
    "\n",
    "azure_cosmosdb_endpoint = os.getenv(\"AZURE_COSMOSDB_ENDPOINT\")\n",
    "azure_cosmosdb_key = os.getenv(\"AZURE_COSMOSDB_KEY\")\n",
    "azure_cosmosdb_database = \"recipes-database\"\n",
    "azure_cosmosdb_container = \"recipes-container\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Azure Cosmos DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cosmos import CosmosClient\n",
    "from azure.cosmos import PartitionKey, exceptions\n",
    "\n",
    "# Setup the connection\n",
    "cosmos_client = CosmosClient(url=azure_cosmosdb_endpoint, credential=azure_cosmosdb_key)\n",
    "\n",
    "# Create database\n",
    "db = cosmos_client.create_database_if_not_exists(id=azure_cosmosdb_database)\n",
    "\n",
    "# Author the vector embedding policy\n",
    "vector_embedding_policy = {\n",
    "    \"vectorEmbeddings\": [\n",
    "        {\n",
    "            \"path\":\"/contentVector\",\n",
    "            \"dataType\":\"float32\",\n",
    "            \"distanceFunction\":\"cosine\",\n",
    "            \"dimensions\":azure_openai_embeddings_size\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "full_text_policy = {\n",
    "   \"defaultLanguage\": \"en-US\",\n",
    "   \"fullTextPaths\": [\n",
    "       {\n",
    "           \"path\": \"/name\",\n",
    "           \"language\": \"en-US\"\n",
    "       },\n",
    "       {\n",
    "           \"path\": \"/description\",\n",
    "           \"language\": \"en-US\"\n",
    "       }\n",
    "   ]\n",
    "}\n",
    "\n",
    "# Add vector indexes to indexing policy\n",
    "indexing_policy = {\n",
    "    \"includedPaths\": [\n",
    "        {\n",
    "            \"path\": \"/*\"\n",
    "        }\n",
    "    ],\n",
    "    \"excludedPaths\": [\n",
    "        {\n",
    "            \"path\": \"/\\\"_etag\\\"/?\"\n",
    "        },\n",
    "        {\n",
    "            \"path\": \"/contentVector/*\"\n",
    "        }\n",
    "    ],\n",
    "    \"fullTextIndexes\": [\n",
    "        {\n",
    "            \"path\": \"/name\"\n",
    "        },\n",
    "        {\n",
    "            \"path\": \"/description\"\n",
    "        }\n",
    "    ],\n",
    "    \"vectorIndexes\": [\n",
    "        {\"path\": \"/contentVector\",\n",
    "         \"type\": \"quantizedFlat\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:    \n",
    "    container = db.create_container_if_not_exists(\n",
    "                    id=azure_cosmosdb_container,\n",
    "                    partition_key=PartitionKey(path='/id', kind='Hash'),\n",
    "                    indexing_policy=indexing_policy,\n",
    "                    vector_embedding_policy=vector_embedding_policy,\n",
    "                    full_text_policy=full_text_policy)\n",
    "\n",
    "    print('Container with id \\'{0}\\' created'.format(id))\n",
    "\n",
    "except exceptions.CosmosResourceExistsError:\n",
    "    print('A container with id \\'{0}\\' already exists'.format(id))\n",
    "\n",
    "container = db.get_container_client(azure_cosmosdb_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating embeddings separately\n",
    "\n",
    "We are computing the embeddings manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "# Azure OpenAI client\n",
    "openai_client = AzureOpenAI(\n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    azure_deployment=azure_openai_embeddings_deployment,\n",
    "    api_key=azure_openai_key)\n",
    "\n",
    "# Read the recipes.json\n",
    "path = os.path.join('data/recipes/', 'recipes.json')\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    recipes = json.load(file)\n",
    "\n",
    "# Convert each recipe dictionary into a formatted string \n",
    "# And store these strings in a list\n",
    "combined_strings = []\n",
    "for recipe in recipes:\n",
    "    combined_string = \"\"\n",
    "    for key, value in recipe.items():\n",
    "        if isinstance(value, list):\n",
    "            combined_string += f\"{key}:\\n\"\n",
    "            for item in value:\n",
    "                combined_string += f\"  - {item}\\n\"\n",
    "        else:\n",
    "            combined_string += f\"{key}: {value}\\n\"\n",
    "    combined_strings.append(combined_string)\n",
    "\n",
    "# Generate embeddings for each combined string\n",
    "content_response = openai_client.embeddings.create(\n",
    "    input=combined_strings, \n",
    "    model=azure_openai_embeddings_deployment, \n",
    "    dimensions=azure_openai_embeddings_size\n",
    ")\n",
    "\n",
    "content_embeddings = [recipe.embedding for recipe in content_response.data]\n",
    "\n",
    "# add contentVector field in recipes\n",
    "for i, item in enumerate(recipes):\n",
    "    item['contentVector'] = content_embeddings[i]\n",
    "\n",
    "# Output embeddings to new json file\n",
    "output_path = os.path.join('data/recipes', 'recipesVectors.json')\n",
    "output_directory = os.path.dirname(output_path)\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(recipes, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data to the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/recipes/recipesVectors.json') as f:\n",
    "   data = json.load(f)\n",
    "\n",
    "container_client = db.get_container_client(azure_cosmosdb_container)\n",
    "\n",
    "for item in data:\n",
    "    print(\"writing item \", item['id'])\n",
    "    container_client.upsert_item(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Search helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from azure.cosmos import CosmosClient\n",
    "\n",
    "# Simple function to assist with hybrid search\n",
    "def hybrid_search(user_query, num_results):\n",
    "\n",
    "    # Setup the connection\n",
    "    cosmos_client = CosmosClient(url=azure_cosmosdb_endpoint, credential=azure_cosmosdb_key)\n",
    "    database = cosmos_client.get_database_client(azure_cosmosdb_database)\n",
    "    container = database.get_container_client(azure_cosmosdb_container)\n",
    "\n",
    "    # Azure OpenAI client\n",
    "    openai_client = AzureOpenAI(\n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    azure_deployment=azure_openai_embeddings_deployment,\n",
    "    api_key=azure_openai_key)\n",
    "\n",
    "    # get embedding of user query\n",
    "    response = openai_client.embeddings.create(input=user_query, \n",
    "                                               model=azure_openai_embeddings_deployment, \n",
    "                                               dimensions=azure_openai_embeddings_size)\n",
    "    embedding = response.data[0].embedding\n",
    "\n",
    "    # format the query\n",
    "    query ='''\n",
    "                SELECT TOP {0} \n",
    "                    c.id, \n",
    "                    c.name,\n",
    "                    c.description,\n",
    "                    c.cuisine,\n",
    "                    c.difficulty,\n",
    "                    c.prepTime,\n",
    "                    c.cookTime,\n",
    "                    c.totalTime,\n",
    "                    c.servings,\n",
    "                    c.ingredients,\n",
    "                    c.instructions, \n",
    "                    VectorDistance(c.contentVector,{1}) AS SimilarityScore \n",
    "                FROM c \n",
    "                ORDER BY RANK RRF \n",
    "                    (VectorDistance(c.contentVector, {1}), FullTextScore(c.description, ['{2}']))\n",
    "            '''.format(num_results, embedding, user_query)\n",
    "    \n",
    "    results = container.query_items(\n",
    "            query=query,\n",
    "            enable_cross_partition_query=True)\n",
    "\n",
    "    # Extract the necessary information from the results\n",
    "    formatted_results = []\n",
    "    for document in results:\n",
    "        score = document.pop('SimilarityScore')\n",
    "        formatted_result = {\n",
    "            'SimilarityScore': score,\n",
    "            'document': document\n",
    "        }\n",
    "        formatted_results.append(formatted_result)\n",
    "\n",
    "    return formatted_results    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Query Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"teas in recipe\"\n",
    "results = hybrid_search(query, 3)\n",
    "\n",
    "for document in results:\n",
    "        print(f\"Similarity Score: {document['SimilarityScore']}\")\n",
    "        print(f\"ID: {document['document']['id']}\")\n",
    "        print(f\"Name: {document['document']['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send query results to a language model to generate response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "# Azure OpenAI client\n",
    "openai_client = AzureOpenAI(\n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    api_key=azure_openai_key)\n",
    "\n",
    "# Provide instructions to the model\n",
    "SYSTEM_PROMPT=\"\"\"\n",
    "You are an AI assistant that helps users learn from the information found in the source material.\n",
    "Answer the query using only the sources provided below.\n",
    "Use bullets if the answer has multiple points.\n",
    "If the answer is longer than 3 sentences, provide a summary.\n",
    "Answer ONLY with the facts listed in the list of sources below. Cite your source when you answer the question\n",
    "If there isn't enough information below, say you don't know.\n",
    "Do not generate answers that don't use the sources below.\n",
    "Query: {query}\n",
    "Sources:\\n{sources}\n",
    "\"\"\"\n",
    "\n",
    "# User Query\n",
    "query = \"What of the recipes use sugar?\"\n",
    "\n",
    "results = hybrid_search(query, 5)\n",
    "\n",
    "# Use a unique separator to make the sources distinct. \n",
    "# We chose repeated equal signs (=) followed by a newline because it's unlikely the source documents contain this sequence.\n",
    "sources_formatted = \"=================\\n\".join(\n",
    "  [f'''Name: {document['document']['name']}, \n",
    "   Description: {document['document']['description']}, \n",
    "   Cuisine: {document['document']['cuisine']},\n",
    "   Difficulty: {document['document']['difficulty']},\n",
    "   Preparation Time: {document['document']['prepTime']},\n",
    "   Cooking Time: {document['document']['cookTime']},\n",
    "   Total Time: {document['document']['totalTime']},\n",
    "   Servings: {document['document']['servings']},\n",
    "   Ingredients: {document['document']['ingredients']},\n",
    "   Instructions: {document['document']['instructions']}'''\n",
    "   for document in results])\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": SYSTEM_PROMPT.format(query=query, sources=sources_formatted)\n",
    "        }\n",
    "    ],\n",
    "    model=azure_openai_deployment\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
